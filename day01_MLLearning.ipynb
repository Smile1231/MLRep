{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datesets_demo():\n",
    "    \"\"\"\n",
    "    sklearn 数据集使用\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 获取数据集\n",
    "    iris = load_iris()\n",
    "    print(\"鸢尾花数据集的返回值：\\n\", iris)\n",
    "    print(\"鸢尾花的描述：\\n\", iris.DESCR)\n",
    "    print(\"鸢尾花特征的名字：\\n\", iris.feature_names)\n",
    "    print(\"鸢尾花的特征值:\\n\", iris.data, iris.data.shape)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    iris = load_iris()\n",
    "    # 数据集划分\n",
    "    # 训练集的特征值x_train 测试集的特征值x_test 训练集的目标值y_train 测试集的目标值y_test\n",
    "    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=22)\n",
    "    print(\"x_train训练集特征值:\\n\", x_train, x_train.shape)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_demo():\n",
    "    \"\"\"\n",
    "    字典特征抽取\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data = [{'city': '北京','temperature':100}, {'city': '上海','temperature':60}, {'city': '深圳','temperature':30}]\n",
    "\n",
    "    # 1. 实例化一个转换器类\n",
    "    transfer = DictVectorizer(sparse=False)\n",
    "\n",
    "    # 2. 调用fit_transform()\n",
    "    data_new = transfer.fit_transform(data)\n",
    "    print(\"data_new:\\n\",data_new)\n",
    "\n",
    "    print(\"特征名字:\\n\",transfer.feature_names_)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_chinese_demo():\n",
    "    #1. new transder\n",
    "    transfer = CountVectorizer()\n",
    "    #2. use fit_transform\n",
    "    data_new = transfer.fit_transform(data)\n",
    "    print(\"文本特征抽取的结果：\\n\", data_new.toarray())\n",
    "    print(\"返回特征名字：\\n\", transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_demo():\n",
    "    \"\"\"\n",
    "    对文本进行特征抽取，countvetorizer\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = [\"life is short,i like like python\", \"life is too long,i dislike python\"]\n",
    "\n",
    "    transfer = CountVectorizer()\n",
    "\n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"文本特征抽取的结果：\\n\", data_new.toarray())\n",
    "    print(\"返回特征名字：\\n\", transfer.get_feature_names())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_chinese_count_demo2():\n",
    "    \"\"\"\n",
    "    对中文进行特征抽取\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    data = [\"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "            \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "            \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"]\n",
    "    data_new = []\n",
    "    for sent in data:\n",
    "            data_new.append(cut_word(sent))\n",
    "\n",
    "    print(data_new)\n",
    "    transfer = CountVectorizer()\n",
    "    #2. use fit_transform\n",
    "    data_final = transfer.fit_transform(data_new)\n",
    "    print(\"文本特征抽取的结果：\\n\", data_final.toarray())\n",
    "    print(\"返回特征名字：\\n\", transfer.get_feature_names())\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_demo():\n",
    "    \"\"\"\n",
    "    归一化演示\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"dating.txt\",sep=\"\\t\")\n",
    "    transfer = MinMaxScaler(feature_range(2, 3))\n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"data_new:\\n\", data_new)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_word(text):\n",
    "    \"\"\"\n",
    "    对中文进行分词\n",
    "    \"我爱北京天安门\"————>\"我 爱 北京 天安门\"\n",
    "    :param text:\n",
    "    :return: text\n",
    "    \"\"\"\n",
    "    # 用结巴对中文字符串进行分词\n",
    "    text = \" \".join(list(jieba.cut(text)))\n",
    "    # a = \" \".join(jieba.cut(text))\n",
    "    # print(a)\n",
    "    # print(type(a))\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stand_demo():\n",
    "    \"\"\"\n",
    "    标准化演示\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"dating.txt\",sep=\"\\t\")\n",
    "    print(data)\n",
    "    # 1、实例化一个转换器类\n",
    "    transfer = StandardScaler()\n",
    "    # 2、调用fit_transform\n",
    "    data = transfer.fit_transform(data[['milage','Liters','Consumtime']])\n",
    "    print(\"标准化的结果:\\n\", data)\n",
    "    print(\"每一列特征的平均值：\\n\", transfer.mean_)\n",
    "    print(\"每一列特征的方差：\\n\", transfer.var_) \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_demo():\n",
    "    \"\"\"\n",
    "    删除低方差特征——特征选择\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(\"factor_returns.csv\")\n",
    "    data = data.iloc[:, 1:-2]\n",
    "    print(\"data:\\n\",data)\n",
    "\n",
    "    transfer = VarianceThreshold(threshold=10)\n",
    "\n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"data_new:\\n\",data_new,data_new.shape)\n",
    "\n",
    "    r = pearsonr(data[\"pe_ratio\"],data[\"pb_ratio\"])\n",
    "\n",
    "    print(\"相关系数:\\n\",r)\n",
    "\n",
    "    \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_demo():\n",
    "    data = [[2,8,4,5], [6,3,0,8], [5,4,9,1]]\n",
    "\n",
    "    transfer = PCA(n_components=2)\n",
    "\n",
    "    data_new = transfer.fit_transform(data)\n",
    "\n",
    "    print(\"data_new:\\n\",data_new)\n",
    "\n",
    "    # 1、实例化PCA, 小数——保留多少信息\n",
    "    transfer1 = PCA(n_components=0.9)\n",
    "    # 2、调用fit_transform\n",
    "    data1 = transfer1.fit_transform(data)\n",
    "\n",
    "    print(\"保留90%的信息，降维结果为：\\n\", data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_new:\n",
      " [[ 1.28620952e-15  3.82970843e+00]\n",
      " [ 5.74456265e+00 -1.91485422e+00]\n",
      " [-5.74456265e+00 -1.91485422e+00]]\n",
      "保留90%的信息，降维结果为：\n",
      " [[ 1.28620952e-15  3.82970843e+00]\n",
      " [ 5.74456265e+00 -1.91485422e+00]\n",
      " [-5.74456265e+00 -1.91485422e+00]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 代码1:sklearn 数据集使用\n",
    "    # split_data()\n",
    "    # dict_demo()\n",
    "    # count_demo()\n",
    "    # cut_word(\"我爱北京天安门\")\n",
    "    # text_chinese_count_demo2()\n",
    "    # stand_demo()\n",
    "    # minmax_demo()\n",
    "    # variance_demo()\n",
    "    pca_demo()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bf0057d5f00d7bc732059372600cc426556a65d87f37fefc9eb64637facecfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dateUse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
